"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Alpha Stack: Russell 2000 Multi-Anomaly ë³µí•© ì „ëµ ë°±í…ŒìŠ¤íŠ¸
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

4-Layer Alpha Stack:
  Layer 1: PEAD (Post-Earnings Announcement Drift)
  Layer 2: Insider Buying + Short Interest Signal
  Layer 3: Neglected Firm Effect (Low Analyst Coverage)
  Layer 4: Quality + Value Safety Net

ë°ì´í„°: yfinance (ë¬´ë£Œ) + OpenInsider (ë¬´ë£Œ)
ì‹¤í–‰: python alpha_stack_backtest.py
"""

import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta
import warnings
import os
import time
import json

warnings.filterwarnings('ignore')

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIG
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CONFIG = {
    # Universe
    'TICKER_SOURCE': 'russell2000_tickers.csv',  # IWM holdings CSV
    'SAMPLE_SIZE': 300,           # í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ (ì „ì²´: None)
    'MIN_MARKET_CAP': 2e8,        # $200M í•˜í•œ
    'MIN_AVG_VOLUME': 5e5,        # ì¼í‰ê·  $500K ê±°ë˜ëŒ€ê¸ˆ

    # Backtest Period
    'START_DATE': '2021-01-01',
    'END_DATE': '2024-12-31',

    # Portfolio
    'TOP_N': 35,                  # í¬íŠ¸í´ë¦¬ì˜¤ ì¢…ëª© ìˆ˜
    'REBALANCE_FREQ': 'monthly',  # monthly or quarterly
    'MAX_SECTOR_PCT': 0.25,       # ì„¹í„°ë‹¹ ìµœëŒ€ ë¹„ì¤‘
    'MAX_STOCK_PCT': 0.04,        # ê°œë³„ ì¢…ëª© ìµœëŒ€

    # Caching
    'CACHE_FILE': 'alpha_stack_cache.pkl',  # ìºì‹œ íŒŒì¼ëª…
    'CACHE_DAYS': 7,              # ìºì‹œ ìœ íš¨ ê¸°ê°„ (ì¼)
    'FORCE_REFRESH': False,       # True = ìºì‹œ ë¬´ì‹œí•˜ê³  ìƒˆë¡œ ë‹¤ìš´ë¡œë“œ

    # Scoring Weights
    'W_PEAD': 0.40,               # PEAD Score ê°€ì¤‘ì¹˜
    'W_INSIDER': 0.30,            # Insider Signal ê°€ì¤‘ì¹˜
    'W_MOMENTUM': 0.30,           # Momentum ê°€ì¤‘ì¹˜
    
    # Transaction Costs
    'TX_COST': 0.004,             # í¸ë„ 0.4% (ì†Œí˜•ì£¼)
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LAYER 4: Quality + Value Safety Net
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def compute_quality_value_filter(ticker_data):
    """
    Quality + Value ì•ˆì „ì¥ì¹˜
    - Gross Profit / Total Assets > ì¤‘ìœ„ê°’ (Novy-Marx Profitability)
    - EV/EBITDA < ì„¹í„° ì¤‘ìœ„ê°’ì˜ 1.5ë°°
    - Altman Z-Score > 1.8 (ë¶€ë„ ìœ„í—˜ ì œê±°)
    """
    scores = {}
    
    for ticker, data in ticker_data.items():
        try:
            info = data.get('info', {})
            
            # Gross Profit / Assets (Novy-Marx Quality)
            gross_profit = info.get('grossProfits', 0) or 0
            total_assets = info.get('totalAssets', 1) or 1
            gp_assets = gross_profit / total_assets if total_assets > 0 else 0
            
            # EV/EBITDA
            ev_ebitda = info.get('enterpriseToEbitda', None)
            if ev_ebitda is None or ev_ebitda <= 0:
                ev_ebitda = 999  # ë°ì´í„° ì—†ìœ¼ë©´ íŒ¨ë„í‹°
            
            # ROE
            roe = info.get('returnOnEquity', 0) or 0
            
            # Debt/Equity
            debt_equity = info.get('debtToEquity', 999) or 999
            
            # Profit Margin
            profit_margin = info.get('profitMargins', 0) or 0
            
            # í†µê³¼ ì¡°ê±´
            passes = (
                gp_assets > 0.15 and          # ì ì • ìˆ˜ìµì„±
                ev_ebitda < 25 and             # ê·¹ë‹¨ì  ê³ í‰ê°€ ì œì™¸
                ev_ebitda > 0 and              # ì ì ê¸°ì—… ì œì™¸
                roe > 0.05 and                 # ìµœì†Œ ROE
                debt_equity < 200 and          # ê³¼ë„í•œ ë¶€ì±„ ì œì™¸
                profit_margin > 0              # í‘ì ê¸°ì—…ë§Œ
            )
            
            if passes:
                # Quality Score (0~100)
                q_score = (
                    min(gp_assets / 0.5, 1.0) * 40 +          # GP/Assets
                    min(roe / 0.3, 1.0) * 30 +                 # ROE
                    max(0, 1 - debt_equity / 200) * 15 +       # Low Debt
                    min(profit_margin / 0.2, 1.0) * 15          # Profit Margin
                )
                
                # Value Score (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ â†’ ì—­ë³€í™˜)
                v_score = max(0, 100 - ev_ebitda * 4)  # EV/EBITDA 25 â†’ 0ì 
                
                scores[ticker] = {
                    'quality_score': q_score,
                    'value_score': v_score,
                    'gp_assets': gp_assets,
                    'ev_ebitda': ev_ebitda,
                    'roe': roe,
                    'debt_equity': debt_equity,
                    'passes_l4': True
                }
        except Exception:
            continue
    
    return scores


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LAYER 3: Neglected Firm Effect
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def compute_coverage_score(ticker_data):
    """
    ì• ë„ë¦¬ìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ê°€ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
    0ëª…: 100ì , 1ëª…: 90ì , 2ëª…: 80ì , ..., 10+ëª…: 0ì 
    """
    scores = {}
    
    for ticker, data in ticker_data.items():
        try:
            info = data.get('info', {})
            num_analysts = info.get('numberOfAnalystOpinions', 0) or 0
            
            # ì»¤ë²„ë¦¬ì§€ ì ìˆ˜: ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
            coverage_score = max(0, 100 - num_analysts * 10)
            
            # ê°€ì : ì™„ì „ ë¯¸ì»¤ë²„ë¦¬ì§€
            bonus = 10 if num_analysts == 0 else 0
            
            scores[ticker] = {
                'num_analysts': num_analysts,
                'coverage_score': min(100, coverage_score + bonus),
                'is_neglected': num_analysts <= 3
            }
        except Exception:
            continue
    
    return scores


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LAYER 1: PEAD (Earnings Surprise Drift)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def compute_pead_score(ticker_data):
    """
    PEAD Score ê³„ì‚°:
    1. Earnings Surprise % (ì‹¤ì œ vs ì˜ˆìƒ)
    2. EAR (Earnings Announcement Return) - ë°œí‘œì¼ Â±1ì¼ ë¹„ì •ìƒìˆ˜ìµë¥ 
    3. ì—°ì† ì„œí”„ë¼ì´ì¦ˆ ê°€ì 
    """
    scores = {}
    
    for ticker, data in ticker_data.items():
        try:
            # yfinanceì—ì„œ earnings ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            stock = data.get('stock_obj')
            if stock is None:
                continue
            
            # Earnings surprise from Yahoo Finance
            earnings = None
            try:
                earnings = stock.earnings_dates
            except:
                pass
            
            if earnings is None or len(earnings) == 0:
                # Fallback: ê°€ê²© ê¸°ë°˜ ëŒ€ë¦¬ ì¸¡ì •
                hist = data.get('history')
                if hist is not None and len(hist) > 60:
                    # ìµœê·¼ ë¶„ê¸°ë³„ ìˆ˜ìµë¥  ë³€ë™ìœ¼ë¡œ ì„œí”„ë¼ì´ì¦ˆ ì¶”ì •
                    recent_return = hist['Close'].pct_change(20).iloc[-1]
                    pead_score = max(0, min(100, 50 + recent_return * 500))
                    scores[ticker] = {
                        'pead_score': pead_score,
                        'surprise_pct': None,
                        'consecutive_beats': 0,
                        'method': 'price_proxy'
                    }
                continue
            
            # Earnings surprise ê³„ì‚°
            surprise_pcts = []
            if 'Surprise(%)' in earnings.columns:
                recent_surprises = earnings['Surprise(%)'].dropna().head(4)
                surprise_pcts = recent_surprises.tolist()
            elif 'EPS Estimate' in earnings.columns and 'Reported EPS' in earnings.columns:
                for _, row in earnings.head(4).iterrows():
                    est = row.get('EPS Estimate')
                    actual = row.get('Reported EPS')
                    if pd.notna(est) and pd.notna(actual) and est != 0:
                        surprise_pcts.append((actual - est) / abs(est) * 100)
            
            if len(surprise_pcts) == 0:
                continue
            
            # ê°€ì¥ ìµœê·¼ ì„œí”„ë¼ì´ì¦ˆ
            latest_surprise = surprise_pcts[0] if surprise_pcts else 0
            
            # ì—°ì† ë¹„íŠ¸ íšŸìˆ˜
            consecutive_beats = 0
            for s in surprise_pcts:
                if s > 0:
                    consecutive_beats += 1
                else:
                    break
            
            # PEAD Score ì‚°ì¶œ
            # ì„œí”„ë¼ì´ì¦ˆê°€ í´ìˆ˜ë¡, ì—°ì† ë¹„íŠ¸ê°€ ë§ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
            surprise_score = max(0, min(100, 50 + latest_surprise * 5))
            beat_bonus = consecutive_beats * 10  # ì—°ì† ë¹„íŠ¸ ê°€ì 
            
            pead_score = min(100, surprise_score + beat_bonus)
            
            scores[ticker] = {
                'pead_score': pead_score,
                'surprise_pct': latest_surprise,
                'consecutive_beats': consecutive_beats,
                'method': 'earnings_data'
            }
            
        except Exception:
            continue
    
    return scores


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LAYER 2: Insider Signal (Simplified - yfinance based)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def compute_insider_score(ticker_data):
    """
    ë‚´ë¶€ì ë§¤ë§¤ ì‹ í˜¸ (yfinance ê¸°ë°˜ ê°„ì†Œí™” ë²„ì „)
    
    ì‹¤ì „ì—ì„œëŠ” SEC EDGAR Form 4 ë˜ëŠ” OpenInsider.com API ì‚¬ìš© ê¶Œì¥
    yfinanceì—ì„œëŠ” insider_transactionsë¡œ ê¸°ë³¸ ë°ì´í„° í™•ë³´ ê°€ëŠ¥
    """
    scores = {}
    
    for ticker, data in ticker_data.items():
        try:
            stock = data.get('stock_obj')
            if stock is None:
                continue
            
            # Insider transactions
            insider_txns = None
            try:
                insider_txns = stock.insider_transactions
            except:
                pass
            
            if insider_txns is None or len(insider_txns) == 0:
                scores[ticker] = {
                    'insider_score': 50,  # ì¤‘ë¦½ (ë°ì´í„° ì—†ìŒ)
                    'net_buys': 0,
                    'cluster_buy': False,
                    'method': 'no_data'
                }
                continue
            
            # ìµœê·¼ 90ì¼ ë‚´ ê±°ë˜ë§Œ
            recent_date = datetime.now() - timedelta(days=90)
            
            # ë§¤ìˆ˜/ë§¤ë„ ê±´ìˆ˜ ë° ê¸ˆì•¡
            buys = 0
            sells = 0
            buy_value = 0
            sell_value = 0
            unique_buyers = set()
            
            for _, txn in insider_txns.iterrows():
                txn_type = str(txn.get('Text', '')).lower()
                shares = abs(txn.get('Shares', 0) or 0)
                value = abs(txn.get('Value', 0) or 0)
                insider = txn.get('Insider', '')
                
                if 'purchase' in txn_type or 'buy' in txn_type:
                    buys += 1
                    buy_value += value
                    unique_buyers.add(insider)
                elif 'sale' in txn_type or 'sell' in txn_type:
                    sells += 1
                    sell_value += value
            
            # Net Buy Ratio
            total_txns = buys + sells
            if total_txns == 0:
                net_buy_ratio = 0
            else:
                net_buy_ratio = (buys - sells) / total_txns
            
            # í´ëŸ¬ìŠ¤í„° ë§¤ìˆ˜ (3ëª… ì´ìƒ ë§¤ìˆ˜)
            cluster_buy = len(unique_buyers) >= 3
            
            # Insider Score ì‚°ì¶œ
            insider_score = 50 + net_buy_ratio * 40  # -50 ~ 90 ê¸°ë³¸
            
            if cluster_buy:
                insider_score += 10  # í´ëŸ¬ìŠ¤í„° ê°€ì 
            
            if buy_value > sell_value * 2:
                insider_score += 10  # ë§¤ìˆ˜ ê¸ˆì•¡ì´ ë§¤ë„ì˜ 2ë°° ì´ìƒ
            
            insider_score = max(0, min(100, insider_score))
            
            scores[ticker] = {
                'insider_score': insider_score,
                'net_buys': buys - sells,
                'buy_value': buy_value,
                'sell_value': sell_value,
                'cluster_buy': cluster_buy,
                'unique_buyers': len(unique_buyers),
                'method': 'yfinance'
            }
            
        except Exception:
            scores[ticker] = {
                'insider_score': 50,
                'net_buys': 0,
                'cluster_buy': False,
                'method': 'error'
            }
    
    return scores


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MOMENTUM (12M - 1M)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def compute_momentum_score(ticker_data):
    """
    12ê°œì›” ìˆ˜ìµë¥  (ìµœê·¼ 1ê°œì›” ì œì™¸) â†’ í•™ìˆ ì  í‘œì¤€ ëª¨ë©˜í…€
    Jegadeesh & Titman (1993) ë°©ë²•ë¡ 
    """
    scores = {}
    
    for ticker, data in ticker_data.items():
        try:
            hist = data.get('history')
            if hist is None or len(hist) < 252:
                continue
            
            prices = hist['Close']
            
            # 12ê°œì›” ì „ ëŒ€ë¹„ ìˆ˜ìµë¥  (ìµœê·¼ 1ê°œì›” ì œì™¸)
            if len(prices) >= 252:
                mom_12m = prices.iloc[-22] / prices.iloc[-252] - 1
            elif len(prices) >= 126:
                mom_12m = prices.iloc[-22] / prices.iloc[0] - 1
            else:
                continue
            
            # ìµœê·¼ 1ê°œì›” ìˆ˜ìµë¥  (ë‹¨ê¸° ë°˜ì „ íš¨ê³¼)
            mom_1m = prices.iloc[-1] / prices.iloc[-22] - 1
            
            # ë³€ë™ì„± ì¡°ì • ëª¨ë©˜í…€
            daily_returns = prices.pct_change().dropna()
            volatility = daily_returns.std() * np.sqrt(252)
            
            risk_adj_momentum = mom_12m / max(volatility, 0.1)
            
            scores[ticker] = {
                'momentum_12m_1m': mom_12m,
                'momentum_1m': mom_1m,
                'volatility': volatility,
                'risk_adj_momentum': risk_adj_momentum
            }
            
        except Exception:
            continue
    
    # Percentile ê¸°ë°˜ ì ìˆ˜í™” (0~100)
    if scores:
        mom_values = [s['momentum_12m_1m'] for s in scores.values()]
        for ticker in scores:
            rank = sum(1 for v in mom_values if v <= scores[ticker]['momentum_12m_1m'])
            scores[ticker]['momentum_score'] = rank / len(mom_values) * 100
    
    return scores


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# COMPOSITE SCORING & PORTFOLIO CONSTRUCTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def compute_composite_score(l4_scores, l3_scores, l1_scores, l2_scores, mom_scores):
    """
    4ê°œ ë ˆì´ì–´ + ëª¨ë©˜í…€ì„ ê²°í•©í•œ ë³µí•© ì ìˆ˜ ì‚°ì¶œ
    """
    composites = {}
    
    # L4ë¥¼ í†µê³¼í•œ ì¢…ëª©ë§Œ ëŒ€ìƒ
    eligible = set(l4_scores.keys())
    
    for ticker in eligible:
        try:
            l4 = l4_scores.get(ticker, {})
            l3 = l3_scores.get(ticker, {})
            l1 = l1_scores.get(ticker, {})
            l2 = l2_scores.get(ticker, {})
            mom = mom_scores.get(ticker, {})
            
            if not l4.get('passes_l4', False):
                continue
            
            # ê° ë ˆì´ì–´ ì ìˆ˜ (0~100)
            pead = l1.get('pead_score', 50)
            insider = l2.get('insider_score', 50)
            momentum = mom.get('momentum_score', 50)
            coverage = l3.get('coverage_score', 50)
            quality = l4.get('quality_score', 50)
            value = l4.get('value_score', 50)
            
            # Alpha Signal Score (Layer 1 + 2 + Momentum)
            alpha_score = (
                pead * CONFIG['W_PEAD'] +
                insider * CONFIG['W_INSIDER'] +
                momentum * CONFIG['W_MOMENTUM']
            )
            
            # Coverage Multiplier (ì €ì»¤ë²„ë¦¬ì§€ ì‹œ ì•ŒíŒŒ ì¦í­)
            coverage_mult = 1.0 + (coverage - 50) / 200  # 0.75 ~ 1.25
            
            # Quality-Value Baseline
            qv_baseline = quality * 0.6 + value * 0.4
            
            # Final Composite
            composite = alpha_score * coverage_mult * 0.7 + qv_baseline * 0.3
            
            composites[ticker] = {
                'composite_score': composite,
                'alpha_score': alpha_score,
                'pead_score': pead,
                'insider_score': insider,
                'momentum_score': momentum,
                'coverage_score': coverage,
                'quality_score': quality,
                'value_score': value,
                'coverage_mult': coverage_mult,
                'num_analysts': l3.get('num_analysts', 0),
                'ev_ebitda': l4.get('ev_ebitda', 0),
                'roe': l4.get('roe', 0),
            }
            
        except Exception:
            continue
    
    return composites


def construct_portfolio(composites, sector_info, top_n=35):
    """
    ì„¹í„° ì œí•œì„ ì ìš©í•œ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±
    """
    # ë³µí•© ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
    sorted_stocks = sorted(composites.items(), 
                          key=lambda x: x[1]['composite_score'], 
                          reverse=True)
    
    portfolio = []
    sector_counts = {}
    max_per_sector = int(top_n * CONFIG['MAX_SECTOR_PCT'])
    
    for ticker, scores in sorted_stocks:
        if len(portfolio) >= top_n:
            break
        
        sector = sector_info.get(ticker, 'Unknown')
        current_count = sector_counts.get(sector, 0)
        
        if current_count < max_per_sector:
            portfolio.append({
                'ticker': ticker,
                'sector': sector,
                **scores
            })
            sector_counts[sector] = current_count + 1
    
    return pd.DataFrame(portfolio)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DATA LOADING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_tickers(filepath=None):
    """Russell 2000 í‹°ì»¤ ë¡œë“œ"""
    if filepath and os.path.exists(filepath):
        df = pd.read_csv(filepath)
        if 'Ticker' in df.columns:
            return df
        elif 'ticker' in df.columns:
            df = df.rename(columns={'ticker': 'Ticker'})
            return df
    
    # Fallback: ëŒ€í‘œ ì†Œí˜•ì£¼ ìƒ˜í”Œ
    print("âš ï¸  russell2000_tickers.csv ì—†ìŒ â†’ ëŒ€í‘œ ì†Œí˜•ì£¼ ìƒ˜í”Œ ì‚¬ìš©")
    sample_tickers = [
        # Tech
        'SMCI','CAMT','AMBA','LSCC','AEIS','VICR','POWI','DIOD','SLAB','CALX',
        'ONTO','RMBS','CEVA','AAON','NOVT','AZTA','DIGI','PRGS','QTWO','ALRM',
        # Healthcare
        'MEDP','HALO','ITCI','KRYS','RVMD','PTCT','TGTX','ACAD','CORT','EXAS',
        'LNTH','NVCR','AXNX','IOVA','INSP','GKOS','NARI','IRTC','AVNS','OFIX',
        # Industrial
        'ATKR','ESAB','SPXC','RBC','PRIM','DY','ROCK','GFF','NPO','POWL',
        'ARCB','MATX','UFPI','TREX','CSGS','AAON','AWI','JBSS','MWA','BMI',
        # Consumer
        'BOOT','SHAK','WING','PLNT','FIZZ','CROX','SKX','FOXF','SFM','CAVA',
        'ELF','LULU','DECK','DKS','COLM','CBRL','PLAY','TXRH','DINE','CAKE',
        # Energy/Materials
        'MTDR','SM','PTEN','HP','RES','CIVI','NOG','GPOR','VNOM','REPX',
        'CLF','ATI','CRS','HAYN','IOSP','KWR','TROX','CC','HUN','NGVT',
        # Financials
        'IBOC','FFIN','SBCF','HOPE','BANF','CVBF','FNB','NBTB','TRMK','UBSI',
        'WTFC','PNFP','GBCI','SFBS','CADE','HWC','WSFS','TOWN','VBTX','WAFD',
        # Real Estate/Utilities
        'AAT','AKR','BRT','CUZ','DEI','EGP','HIW','KRG','NNN','OHI',
        'PINE','ROIC','SHO','UMH','VRE','BKH','NWE','OGS','PNM','SJW',
    ]
    
    # ì„¹í„° ë§¤í•‘
    sector_map = {}
    sectors = ['Technology']*20 + ['Healthcare']*20 + ['Industrials']*20 + \
              ['Consumer']*20 + ['Energy']*20 + ['Financials']*20 + ['REIT/Utilities']*20
    for i, t in enumerate(sample_tickers):
        sector_map[t] = sectors[i] if i < len(sectors) else 'Other'
    
    df = pd.DataFrame({
        'Ticker': sample_tickers,
        'Sector': [sector_map.get(t, 'Other') for t in sample_tickers]
    })
    return df


def load_cache(cache_file, max_age_days):
    """ìºì‹œ íŒŒì¼ ë¡œë“œ"""
    if not os.path.exists(cache_file):
        print(f"   ìºì‹œ íŒŒì¼ ì—†ìŒ: {cache_file}")
        return None

    import pickle
    file_age_days = (datetime.now() - datetime.fromtimestamp(os.path.getmtime(cache_file))).days
    file_size_mb = os.path.getsize(cache_file) / (1024 * 1024)

    if file_age_days > max_age_days:
        print(f"   âš ï¸  ìºì‹œ ë§Œë£Œ: {file_age_days}ì¼ ê²½ê³¼ (ìµœëŒ€ {max_age_days}ì¼)")
        return None

    try:
        print(f"   ğŸ“‚ ìºì‹œ íŒŒì¼ ë°œê²¬: {cache_file}")
        print(f"      í¬ê¸°: {file_size_mb:.1f} MB | ìƒì„±: {file_age_days}ì¼ ì „")
        print(f"   â³ ìºì‹œ ë¡œë”© ì¤‘...")

        with open(cache_file, 'rb') as f:
            data = pickle.load(f)

        print(f"   âœ… ìºì‹œ ë¡œë“œ ì™„ë£Œ: {len(data)}ê°œ ì¢…ëª© ë°ì´í„°")
        return data
    except Exception as e:
        print(f"   âš ï¸  ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def save_cache(data, cache_file):
    """ìºì‹œ íŒŒì¼ ì €ì¥"""
    import pickle
    try:
        print(f"\nğŸ’¾ ìºì‹œ ì €ì¥ ì¤‘: {len(data)}ê°œ ì¢…ëª©...")
        with open(cache_file, 'wb') as f:
            pickle.dump(data, f)

        file_size_mb = os.path.getsize(cache_file) / (1024 * 1024)
        print(f"   âœ… ì €ì¥ ì™„ë£Œ: {cache_file} ({file_size_mb:.1f} MB)")
        print(f"   ìœ íš¨ê¸°ê°„: {CONFIG['CACHE_DAYS']}ì¼")
    except Exception as e:
        print(f"   âš ï¸  ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")


def fetch_stock_data(tickers, period='2y'):
    """ì£¼ê°€ ë° ê¸°ë³¸ ì •ë³´ ë‹¤ìš´ë¡œë“œ"""
    ticker_data = {}
    total = len(tickers)
    start_time = time.time()

    print(f"\nğŸ“Š {total}ê°œ ì¢…ëª© ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
    print(f"   ì˜ˆìƒ ì†Œìš” ì‹œê°„: ~{total * 0.15 / 60:.1f}ë¶„ (í‰ê·  0.15ì´ˆ/ì¢…ëª©)")
    print(f"   ì§„í–‰ ìƒí™©:")

    for i, ticker in enumerate(tickers):
        # Show progress every 10 stocks or at milestones
        if (i + 1) % 10 == 0 or (i + 1) in [1, 5, total]:
            elapsed = time.time() - start_time
            progress_pct = (i + 1) / total * 100
            valid_count = len(ticker_data)

            # Calculate ETA
            if i > 0:
                avg_time_per_stock = elapsed / (i + 1)
                remaining_stocks = total - (i + 1)
                eta_seconds = avg_time_per_stock * remaining_stocks
                eta_min = eta_seconds / 60

                print(f"   [{i+1:4d}/{total}] {progress_pct:5.1f}% | "
                      f"ìœ íš¨: {valid_count:3d} | "
                      f"ê²½ê³¼: {elapsed/60:4.1f}ë¶„ | "
                      f"ë‚¨ì€ì‹œê°„: ~{eta_min:4.1f}ë¶„")
            else:
                print(f"   [{i+1:4d}/{total}] {progress_pct:5.1f}% | ìœ íš¨: {valid_count:3d}")

        try:
            stock = yf.Ticker(ticker)
            hist = stock.history(period=period)

            if hist is None or len(hist) < 60:
                continue

            info = {}
            try:
                info = stock.info
            except:
                pass

            # ì‹œê°€ì´ì•¡ & ê±°ë˜ëŸ‰ í•„í„°
            market_cap = info.get('marketCap', 0) or 0
            avg_volume = info.get('averageVolume', 0) or 0
            current_price = hist['Close'].iloc[-1] if len(hist) > 0 else 0
            avg_dollar_volume = avg_volume * current_price

            if market_cap < CONFIG['MIN_MARKET_CAP']:
                continue
            if avg_dollar_volume < CONFIG['MIN_AVG_VOLUME']:
                continue

            ticker_data[ticker] = {
                'stock_obj': stock,
                'history': hist,
                'info': info,
                'market_cap': market_cap,
            }

            # Rate limiting
            time.sleep(0.1)

        except Exception as e:
            continue

    elapsed_total = time.time() - start_time
    print(f"\n   âœ… ì™„ë£Œ: {len(ticker_data)}ê°œ ì¢…ëª© ë°ì´í„° í™•ë³´ (ì´ {elapsed_total/60:.1f}ë¶„ ì†Œìš”)")
    return ticker_data


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BACKTEST ENGINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_backtest(ticker_data, composites, sector_info, start_date, end_date, top_n=35):
    """
    ê°„ì†Œí™”ëœ ë°±í…ŒìŠ¤íŠ¸ (ë‹¨ì¼ ê¸°ê°„)
    
    ì‹¤ì „ì—ì„œëŠ” rolling windowë¡œ ë§¤ì›” ë¦¬ë°¸ëŸ°ì‹±í•´ì•¼ í•˜ì§€ë§Œ,
    yfinance ì œì•½ìƒ ë‹¨ì¼ ìŠ¤ëƒ…ìƒ· ê¸°ë°˜ìœ¼ë¡œ êµ¬í˜„
    """
    print("\nğŸ”„ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
    
    # í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±
    portfolio_df = construct_portfolio(composites, sector_info, top_n)
    
    if len(portfolio_df) == 0:
        print("âŒ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ì‹¤íŒ¨")
        return None, None, portfolio_df
    
    print(f"   í¬íŠ¸í´ë¦¬ì˜¤: {len(portfolio_df)}ê°œ ì¢…ëª©")
    
    # ë™ì¼ê°€ì¤‘ í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚°
    portfolio_returns = []
    benchmark_returns = []
    
    start = pd.to_datetime(start_date)
    end = pd.to_datetime(end_date)
    
    # í¬íŠ¸í´ë¦¬ì˜¤ ì¢…ëª© ì¼ë³„ ìˆ˜ìµë¥ 
    daily_returns_list = []
    for _, row in portfolio_df.iterrows():
        ticker = row['ticker']
        if ticker in ticker_data:
            hist = ticker_data[ticker]['history']
            if hist is not None and len(hist) > 0:
                ret = hist['Close'].pct_change().dropna()
                # Remove timezone to avoid comparison issues
                if ret.index.tz is not None:
                    ret.index = ret.index.tz_localize(None)
                ret = ret[ret.index >= start]
                ret = ret[ret.index <= end]
                ret.name = ticker
                daily_returns_list.append(ret)
    
    if len(daily_returns_list) == 0:
        print("âŒ ìˆ˜ìµë¥  ë°ì´í„° ì—†ìŒ")
        return None, None, portfolio_df
    
    # ë™ì¼ê°€ì¤‘ í¬íŠ¸í´ë¦¬ì˜¤
    returns_df = pd.concat(daily_returns_list, axis=1)
    portfolio_daily = returns_df.mean(axis=1)
    
    # ê±°ë˜ë¹„ìš© ì°¨ê° (ì›” 1íšŒ ë¦¬ë°¸ëŸ°ì‹±, í‰ê·  30% êµì²´ìœ¨ ê°€ì •)
    monthly_cost = CONFIG['TX_COST'] * 2 * 0.30  # í¸ë„ë¹„ìš© Ã— ì™•ë³µ Ã— êµì²´ìœ¨
    daily_cost = monthly_cost / 21  # ê±°ë˜ì¼ ê¸°ì¤€
    portfolio_daily = portfolio_daily - daily_cost
    
    # ë²¤ì¹˜ë§ˆí¬: IWM (Russell 2000 ETF)
    try:
        iwm = yf.Ticker('IWM')
        iwm_hist = iwm.history(start=start, end=end)
        benchmark_daily = iwm_hist['Close'].pct_change().dropna()
    except:
        benchmark_daily = pd.Series(0, index=portfolio_daily.index)
    
    # ì¸ë±ìŠ¤ ë§ì¶”ê¸°
    common_idx = portfolio_daily.index.intersection(benchmark_daily.index)
    portfolio_daily = portfolio_daily[common_idx]
    benchmark_daily = benchmark_daily[common_idx]
    
    return portfolio_daily, benchmark_daily, portfolio_df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PERFORMANCE ANALYTICS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def calculate_metrics(returns):
    """ì„±ê³¼ ì§€í‘œ ê³„ì‚°"""
    if returns is None or len(returns) == 0:
        return {}
    
    total_return = (1 + returns).prod() - 1
    n_years = len(returns) / 252
    cagr = (1 + total_return) ** (1 / max(n_years, 0.01)) - 1
    volatility = returns.std() * np.sqrt(252)
    sharpe = (cagr - 0.04) / max(volatility, 0.001)  # RF=4%
    
    # Max Drawdown
    cum_returns = (1 + returns).cumprod()
    rolling_max = cum_returns.expanding().max()
    drawdowns = cum_returns / rolling_max - 1
    max_dd = drawdowns.min()
    
    # Sortino Ratio
    downside = returns[returns < 0].std() * np.sqrt(252)
    sortino = (cagr - 0.04) / max(downside, 0.001)
    
    # Win Rate
    win_rate = (returns > 0).mean()
    
    return {
        'Total Return': f"{total_return:.2%}",
        'CAGR': f"{cagr:.2%}",
        'Volatility': f"{volatility:.2%}",
        'Sharpe Ratio': f"{sharpe:.2f}",
        'Sortino Ratio': f"{sortino:.2f}",
        'Max Drawdown': f"{max_dd:.2%}",
        'Win Rate (Daily)': f"{win_rate:.2%}",
        'Trading Days': len(returns),
    }


def print_results(strategy_metrics, benchmark_metrics, portfolio_df):
    """ê²°ê³¼ ì¶œë ¥"""
    print("\n" + "â•" * 70)
    print("  ğŸ“Š Alpha Stack ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼")
    print("â•" * 70)
    
    print(f"\n{'ì§€í‘œ':<25} {'ì „ëµ':>15} {'ë²¤ì¹˜ë§ˆí¬(IWM)':>15}")
    print("-" * 55)
    
    for key in strategy_metrics:
        s_val = strategy_metrics.get(key, 'N/A')
        b_val = benchmark_metrics.get(key, 'N/A')
        print(f"{key:<25} {s_val:>15} {b_val:>15}")
    
    print(f"\n{'â”€' * 55}")
    print(f"  í¬íŠ¸í´ë¦¬ì˜¤ ì¢…ëª© ìˆ˜: {len(portfolio_df)}")
    
    if len(portfolio_df) > 0:
        print(f"\n  ğŸ“ˆ ìƒìœ„ 10ê°œ ì¢…ëª© (ë³µí•© ì ìˆ˜ ê¸°ì¤€):")
        print(f"  {'Ticker':<8} {'Composite':>10} {'PEAD':>8} {'Insider':>8} {'Mom':>8} {'Coverage':>8}")
        print(f"  {'-'*50}")
        for _, row in portfolio_df.head(10).iterrows():
            print(f"  {row['ticker']:<8} {row['composite_score']:>10.1f} "
                  f"{row['pead_score']:>8.1f} {row['insider_score']:>8.1f} "
                  f"{row['momentum_score']:>8.1f} {row['coverage_score']:>8.1f}")
        
        print(f"\n  ğŸ¢ ì„¹í„° ë¶„í¬:")
        sector_dist = portfolio_df['sector'].value_counts()
        for sector, count in sector_dist.items():
            pct = count / len(portfolio_df) * 100
            bar = 'â–ˆ' * int(pct / 2)
            print(f"  {sector:<20} {count:>3}ê°œ ({pct:>5.1f}%) {bar}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VISUALIZATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_charts(portfolio_returns, benchmark_returns, portfolio_df, output_dir='.'):
    """ê²°ê³¼ ì°¨íŠ¸ ìƒì„±"""
    try:
        # Remove timezone to avoid comparison issues
        if portfolio_returns.index.tz is not None:
            portfolio_returns.index = portfolio_returns.index.tz_localize(None)
        if benchmark_returns.index.tz is not None:
            benchmark_returns.index = benchmark_returns.index.tz_localize(None)

        import matplotlib
        matplotlib.use('Agg')
        import matplotlib.pyplot as plt

        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('Alpha Stack: Russell 2000 Multi-Anomaly Strategy', 
                     fontsize=16, fontweight='bold', y=0.98)
        
        # 1. ëˆ„ì  ìˆ˜ìµë¥ 
        ax = axes[0, 0]
        port_cum = (1 + portfolio_returns).cumprod()
        bench_cum = (1 + benchmark_returns).cumprod()
        ax.plot(port_cum.index, port_cum.values, label='Alpha Stack', 
                linewidth=2.5, color='#1a73e8')
        ax.plot(bench_cum.index, bench_cum.values, label='IWM (Russell 2000)', 
                linewidth=2, color='#ea4335', alpha=0.7)
        ax.fill_between(port_cum.index, port_cum.values, bench_cum.values,
                       where=port_cum.values >= bench_cum.values, 
                       color='#1a73e8', alpha=0.1)
        ax.set_title('Cumulative Returns', fontsize=13, fontweight='bold')
        ax.set_ylabel('Growth of $1')
        ax.legend(loc='upper left')
        ax.grid(True, alpha=0.3)
        
        # 2. ë“œë¡œìš°ë‹¤ìš´
        ax = axes[0, 1]
        rolling_max = port_cum.expanding().max()
        drawdown = (port_cum / rolling_max - 1) * 100
        ax.fill_between(drawdown.index, drawdown.values, 0, 
                       color='#ea4335', alpha=0.5)
        bench_rm = bench_cum.expanding().max()
        bench_dd = (bench_cum / bench_rm - 1) * 100
        ax.plot(bench_dd.index, bench_dd.values, color='gray', 
                alpha=0.5, label='IWM Drawdown')
        ax.set_title('Drawdown Comparison', fontsize=13, fontweight='bold')
        ax.set_ylabel('Drawdown (%)')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 3. ì›”ë³„ ì´ˆê³¼ìˆ˜ìµ
        ax = axes[1, 0]
        port_monthly = portfolio_returns.resample('M').apply(lambda x: (1+x).prod() - 1)
        bench_monthly = benchmark_returns.resample('ME').apply(lambda x: (1+x).prod() - 1)
        common = port_monthly.index.intersection(bench_monthly.index)
        excess = port_monthly[common] - bench_monthly[common]
        colors = ['#ea4335' if x < 0 else '#34a853' for x in excess.values]
        ax.bar(range(len(excess)), excess.values * 100, color=colors, alpha=0.7)
        ax.axhline(y=0, color='black', linewidth=0.5)
        ax.set_title('Monthly Excess Returns vs IWM', fontsize=13, fontweight='bold')
        ax.set_ylabel('Excess Return (%)')
        ax.grid(True, alpha=0.3, axis='y')
        
        # 4. Alpha Layer ê¸°ì—¬ë„
        ax = axes[1, 1]
        if len(portfolio_df) > 0:
            layer_means = {
                'PEAD\n(Layer 1)': portfolio_df['pead_score'].mean(),
                'Insider\n(Layer 2)': portfolio_df['insider_score'].mean(),
                'Coverage\n(Layer 3)': portfolio_df['coverage_score'].mean(),
                'Quality\n(Layer 4)': portfolio_df['quality_score'].mean(),
                'Momentum': portfolio_df['momentum_score'].mean(),
            }
            colors_radar = ['#1a73e8', '#ea4335', '#fbbc04', '#34a853', '#9c27b0']
            bars = ax.barh(list(layer_means.keys()), list(layer_means.values()), 
                          color=colors_radar, alpha=0.8, height=0.6)
            ax.set_xlim(0, 100)
            ax.set_title('Average Layer Scores (Portfolio)', fontsize=13, fontweight='bold')
            ax.set_xlabel('Score (0-100)')
            for bar, val in zip(bars, layer_means.values()):
                ax.text(val + 1, bar.get_y() + bar.get_height()/2, 
                       f'{val:.0f}', va='center', fontweight='bold')
        
        plt.tight_layout()
        chart_path = os.path.join(output_dir, 'alpha_stack_results.png')
        plt.savefig(chart_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"\nğŸ“Š ì°¨íŠ¸ ì €ì¥: {chart_path}")
        
    except ImportError:
        print("âš ï¸  matplotlib ë¯¸ì„¤ì¹˜ - ì°¨íŠ¸ ìƒëµ")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    import sys

    # ì»¤ë§¨ë“œ ë¼ì¸ ì¸ì ì²˜ë¦¬
    if '--refresh' in sys.argv or '-r' in sys.argv:
        CONFIG['FORCE_REFRESH'] = True
        print("ê°•ì œ ìƒˆë¡œê³ ì¹¨ ëª¨ë“œ\n")

    print("â•" * 70)
    print("  ğŸš€ Alpha Stack: Russell 2000 Multi-Anomaly ì „ëµ ë°±í…ŒìŠ¤íŠ¸")
    print("  â”€â”€ 4-Layer Alpha Stacking Strategy â”€â”€")
    print("â•" * 70)
    print(f"\n  ì„¤ì •:")
    print(f"  â”œ ê¸°ê°„: {CONFIG['START_DATE']} ~ {CONFIG['END_DATE']}")
    print(f"  â”œ í¬íŠ¸í´ë¦¬ì˜¤: ìƒìœ„ {CONFIG['TOP_N']}ê°œ ë™ì¼ê°€ì¤‘")
    print(f"  â”œ ê°€ì¤‘ì¹˜: PEAD {CONFIG['W_PEAD']:.0%} / Insider {CONFIG['W_INSIDER']:.0%} / Mom {CONFIG['W_MOMENTUM']:.0%}")
    print(f"  â”” ê±°ë˜ë¹„ìš©: í¸ë„ {CONFIG['TX_COST']:.1%}")
    
    # 1. í‹°ì»¤ ë¡œë“œ
    ticker_df = load_tickers(CONFIG['TICKER_SOURCE'])
    tickers = ticker_df['Ticker'].tolist()
    
    sector_info = {}
    if 'Sector' in ticker_df.columns:
        sector_info = dict(zip(ticker_df['Ticker'], ticker_df['Sector']))
    
    # ìƒ˜í”Œë§
    if CONFIG['SAMPLE_SIZE'] and CONFIG['SAMPLE_SIZE'] < len(tickers):
        np.random.seed(42)
        tickers = list(np.random.choice(tickers, CONFIG['SAMPLE_SIZE'], replace=False))
        print(f"\n  âš¡ {CONFIG['SAMPLE_SIZE']}ê°œ ìƒ˜í”Œë¡œ í…ŒìŠ¤íŠ¸")

    # 2. ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ìºì‹œ ì‚¬ìš©)
    print("\n" + "â”€" * 70)
    print("ğŸ“¦ ë°ì´í„° ë¡œë”©")
    print("â”€" * 70)

    ticker_data = None

    if not CONFIG['FORCE_REFRESH']:
        print(f"ğŸ” ìºì‹œ íŒŒì¼ í™•ì¸: {CONFIG['CACHE_FILE']}")
        ticker_data = load_cache(CONFIG['CACHE_FILE'], CONFIG['CACHE_DAYS'])

    if ticker_data is None:
        if CONFIG['FORCE_REFRESH']:
            print("ğŸ”„ ê°•ì œ ìƒˆë¡œê³ ì¹¨: ìºì‹œë¥¼ ë¬´ì‹œí•˜ê³  ìƒˆ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤...")
        else:
            print("ğŸ“¥ ìºì‹œ ì—†ìŒ: ìƒˆ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤...")
        print(f"   ëŒ€ìƒ ì¢…ëª© ìˆ˜: {len(tickers)}ê°œ")
        ticker_data = fetch_stock_data(tickers)
        save_cache(ticker_data, CONFIG['CACHE_FILE'])
    else:
        print(f"âœ… ìºì‹œëœ ë°ì´í„° ì‚¬ìš© ({len(ticker_data)}ê°œ ì¢…ëª©)")
        print(f"   ë‹¤ìŒ ìƒˆë¡œê³ ì¹¨ê¹Œì§€: {CONFIG['CACHE_DAYS']}ì¼ ì´ë‚´")
        print(f"   ê°•ì œ ìƒˆë¡œê³ ì¹¨: --refresh í”Œë˜ê·¸ ì‚¬ìš©")

    if len(ticker_data) < 20:
        print(f"âŒ ì¶©ë¶„í•œ ë°ì´í„° ì—†ìŒ ({len(ticker_data)}ê°œ)")
        return
    
    # 3. Layer 4: Quality + Value Filter
    print("\nğŸ›¡ï¸  Layer 4: Quality + Value í•„í„°ë§...")
    l4_scores = compute_quality_value_filter(ticker_data)
    passed = sum(1 for s in l4_scores.values() if s.get('passes_l4'))
    print(f"   í†µê³¼: {passed}/{len(ticker_data)}")
    
    # 4. Layer 3: Coverage Score
    print("\nğŸ” Layer 3: ì»¤ë²„ë¦¬ì§€ ì ìˆ˜ ì‚°ì¶œ...")
    l3_scores = compute_coverage_score(ticker_data)
    neglected = sum(1 for s in l3_scores.values() if s.get('is_neglected'))
    print(f"   ì €ì»¤ë²„ë¦¬ì§€(â‰¤3ëª…): {neglected}/{len(l3_scores)}")
    
    # 5. Layer 1: PEAD Score
    print("\nğŸ¯ Layer 1: PEAD ì ìˆ˜ ì‚°ì¶œ...")
    l1_scores = compute_pead_score(ticker_data)
    print(f"   PEAD ë°ì´í„°: {len(l1_scores)}ê°œ")
    
    # 6. Layer 2: Insider Score
    print("\nğŸ•µï¸  Layer 2: ë‚´ë¶€ì ë§¤ë§¤ ì ìˆ˜ ì‚°ì¶œ...")
    l2_scores = compute_insider_score(ticker_data)
    net_positive = sum(1 for s in l2_scores.values() if s.get('net_buys', 0) > 0)
    print(f"   ìˆœë§¤ìˆ˜ ì¢…ëª©: {net_positive}/{len(l2_scores)}")
    
    # 7. Momentum Score
    print("\nğŸ“ˆ Momentum ì ìˆ˜ ì‚°ì¶œ...")
    mom_scores = compute_momentum_score(ticker_data)
    print(f"   ëª¨ë©˜í…€ ë°ì´í„°: {len(mom_scores)}ê°œ")
    
    # 8. Composite Score
    print("\nğŸ° ë³µí•© ì ìˆ˜ ì‚°ì¶œ...")
    composites = compute_composite_score(l4_scores, l3_scores, l1_scores, 
                                         l2_scores, mom_scores)
    print(f"   ìµœì¢… í›„ë³´: {len(composites)}ê°œ")
    
    # 9. Backtest
    portfolio_returns, benchmark_returns, portfolio_df = run_backtest(
        ticker_data, composites, sector_info,
        CONFIG['START_DATE'], CONFIG['END_DATE'],
        CONFIG['TOP_N']
    )
    
    if portfolio_returns is None:
        print("âŒ ë°±í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return
    
    # 10. Results
    strategy_metrics = calculate_metrics(portfolio_returns)
    benchmark_metrics = calculate_metrics(benchmark_returns)
    print_results(strategy_metrics, benchmark_metrics, portfolio_df)
    
    # 11. Charts
    create_charts(portfolio_returns, benchmark_returns, portfolio_df)
    
    # 12. Save
    portfolio_df.to_csv('alpha_stack_portfolio.csv', index=False)
    
    results = pd.DataFrame({
        'Date': portfolio_returns.index,
        'Strategy': portfolio_returns.values,
        'Benchmark': benchmark_returns.values
    })
    results.to_csv('alpha_stack_daily_returns.csv', index=False)
    
    print("\nğŸ“ ì €ì¥ëœ íŒŒì¼:")
    print("   - alpha_stack_portfolio.csv (í¬íŠ¸í´ë¦¬ì˜¤)")
    print("   - alpha_stack_daily_returns.csv (ì¼ë³„ ìˆ˜ìµë¥ )")
    print("   - alpha_stack_results.png (ì°¨íŠ¸)")
    
    print("\n" + "â•" * 70)
    print("  âœ… Alpha Stack ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("â•" * 70)


if __name__ == "__main__":
    main()
